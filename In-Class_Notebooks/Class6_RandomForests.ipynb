{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKI6RfSaQveE"
      },
      "source": [
        "## Class 6: Random Forests\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zwy90vCrQveH"
      },
      "source": [
        "A few examples are reproduced or adapted from\n",
        "\n",
        "https://github.com/jakevdp/PythonDataScienceHandbook\n",
        "\n",
        "The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z09JwxA5QveH"
      },
      "source": [
        "# 1.  $\\underline{{\\rm Random\\ Forest\\ Classifier}}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2hQGTBzQveI"
      },
      "outputs": [],
      "source": [
        "#Let's start with our imports, you might notice some new ones\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold, KFold, cross_validate\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV_WQMwjQveJ"
      },
      "source": [
        "## 1.1 Why choose an ensemble method (such as a RF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6YoRJAAQveJ"
      },
      "source": [
        "Let's make up some data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfC0roVEQveJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_blobs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybrmmZQ8QveK"
      },
      "outputs": [],
      "source": [
        "pos, colors = make_blobs(n_samples=500, centers=4,\n",
        "                  random_state=0, cluster_std=1.5)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.scatter(pos[:, 0], pos[:, 1], c=colors, s=50, cmap='rainbow');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iqxKgN5QveK"
      },
      "source": [
        "How should we attack this problem as a classification problem? But first, why might we need an ensemble learning method and not just a single decsion tress?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SB8i3678QveK"
      },
      "source": [
        "We can see that there are several areas of overlapping. How might one single tree make these splits?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0x3yc1kQveK"
      },
      "source": [
        "Let's do a 5 fold cross validation with a decision tree to get an idea of the performance and whether we are suffering from high bias or high variance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wefLHh9QveL"
      },
      "outputs": [],
      "source": [
        "#I'm going to make a random seed to use throughout my whole notebbok!\n",
        "seed = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1ekP9DAQveL"
      },
      "outputs": [],
      "source": [
        "model = DecisionTreeClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTTq3MkBQveL"
      },
      "outputs": [],
      "source": [
        "cv = KFold(n_splits=5, shuffle=True, random_state=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktnzZal-QveL"
      },
      "outputs": [],
      "source": [
        "scores = cross_validate(model, pos, colors, cv=cv, scoring = 'accuracy', \\\n",
        "                        return_train_score = True)\n",
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07L1lPY-QveL"
      },
      "outputs": [],
      "source": [
        "    test = scores['test_score']\n",
        "    train = scores['train_score']\n",
        "\n",
        "    print('Test scores:', test.mean(), test.std())\n",
        "    print('Train scores:', train.mean(), train.std())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSuSL3tSQveL"
      },
      "source": [
        "Let's take a look at our scores. Are they within one standard deviation? What dow we think about the difference between the training and test scores?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTXzCD_YQveL"
      },
      "source": [
        "While the dataset seems balanced, in which case bias is low, there seems to be some high variance (over fitting). This is where a Random forest could come in handy!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDlv-LeyQveL"
      },
      "source": [
        "Let's do the same thing as above but using a Random Forest with standard parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHK9UuypQveL"
      },
      "outputs": [],
      "source": [
        "model_rf = RandomForestClassifier(n_estimators=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0nQaDHYQveL"
      },
      "outputs": [],
      "source": [
        "scores = cross_validate(model_rf, pos, colors, cv=cv, scoring = 'accuracy', \\\n",
        "                        return_train_score = True)\n",
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWIzMDIPQveM"
      },
      "outputs": [],
      "source": [
        "test = scores['test_score']\n",
        "train = scores['train_score']\n",
        "\n",
        "print('Test scores:', test.mean(), test.std())\n",
        "print('Train scores:', train.mean(), train.std())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzxL5IltQveM"
      },
      "source": [
        "Ok, while those aren't great scores, we can see that the RF performed slightly better.\n",
        "#### A Random Forest ensemble characteristic lessens overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHSyt7eOQveM"
      },
      "source": [
        "## 1.2 Hyperparameter tuning with a Grid Search\n",
        "\n",
        "Scikiit-learn comes with great buil-in finctions that search the parameter space of hyperparameters to find combinations that result in the best model. Let's see how it's implimented."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nl4sILNPQveM"
      },
      "source": [
        "We begin by creating a dictionary that holds all of the hyperparameters we want to explore."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64KM1UP4QveM"
      },
      "outputs": [],
      "source": [
        "### LET'S DESCIBE THE SYNTAX\n",
        "hyperparam_grid = {\n",
        "'max_depth': [7,15],\n",
        "#'max_features': [2, 4],\n",
        "'min_samples_leaf': [2, 5, 10],\n",
        "#'min_samples_split': [2,3, 5],\n",
        "'n_estimators': [50, 100]\n",
        "}\n",
        "### AND THERE ARE SO MANY MORE OPTIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6RL5ea1QveS"
      },
      "source": [
        "#### Note: The typical hyperparameters that one tunes in RF are: n_estimators, min_samples_leaf, min_samples_split, max_depth, and max_features.\n",
        "\n",
        "n_estimators (number of trees) increasing number of trees is typycally good but at some point it doesn't get any better and more trees=more time.\n",
        "\n",
        "max_features is a good parameter to explore (it's the size of the subset of random features used to create splits) but in this data set there are only two features so not much fun.\n",
        "\n",
        "min_samples_split and min_samples_leaf are the minimum amount of examples that need to be in each split/leaf node. Setting one of these parameters to a higher number (with respect to their default values of 2/1 respectively) is a great way to avoid overfitting.\n",
        "\n",
        "Max_depth is the maximum number of splits in a tree. This is also a good parameter to tune to avoid overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KEqfqNWQveM"
      },
      "source": [
        "#### Now we create a variable that will hold the result of our grid search, like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXqiFGRCQveM"
      },
      "outputs": [],
      "source": [
        "search_1 = GridSearchCV(estimator=RandomForestClassifier(), param_grid = hyperparam_grid,\\\n",
        "                        scoring='recall_weighted', cv = cv, verbose = 1,\\\n",
        "                           return_train_score=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DUS6NhzQveM"
      },
      "outputs": [],
      "source": [
        "### this is for timing how long my code takes\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWyyvyBbQveM"
      },
      "source": [
        "And we perform the search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BlzLuWEQveM"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "search_1.fit(pos, colors)\n",
        "print('number of minutes to perform the serach:', (time.time() - start)/60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIKjFt4tQveM"
      },
      "outputs": [],
      "source": [
        "print('mean test scores:',search_1.cv_results_['mean_test_score'])\n",
        "print('std test scores:',search_1.cv_results_['std_test_score'])\n",
        "print('mean train scores:',search_1.cv_results_['mean_train_score'])\n",
        "print('std train scores:',search_1.cv_results_['std_train_score'])\n",
        "print('best test score:',search_1.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NxT-9v0QveM"
      },
      "source": [
        "So what do we notice?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvYj56yuQveN"
      },
      "source": [
        "And now let's see what best hyperparameter values our serach found:`m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rG32eRmUQveN"
      },
      "outputs": [],
      "source": [
        "results_1 = search_1.best_params_\n",
        "results_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lElArwDdQveN"
      },
      "source": [
        "Ok! Let's create a model and train.\n",
        "\n",
        "First thing's first... split the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxd1zeZWQveN"
      },
      "outputs": [],
      "source": [
        "### WHAT ARE OUR FEATURES AND TARGETS???\n",
        "features = pos\n",
        "target   = colors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Si-9YjgjQveN"
      },
      "outputs": [],
      "source": [
        "### Another way to compliment looking at a visual representation of a distribution is to use np.unique\n",
        "### to get numerical values\n",
        "\n",
        "classes, counts = np.unique(target, return_counts=True)\n",
        "print(classes)\n",
        "print(counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5jzFeanQveN"
      },
      "source": [
        "So we see we have 4 classes  - 0,1,2,3 - and they each have 125 data points (instances) in each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrNj8RAGQveS"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2,\\\n",
        "                                                    random_state=seed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(y_train, return_counts=True)"
      ],
      "metadata": {
        "id": "TXaCf7T8GOZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(y_test, return_counts=True)"
      ],
      "metadata": {
        "id": "44gmSJTPGVlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdpnIGuHQveS"
      },
      "outputs": [],
      "source": [
        "### LET\"S BUILD OUR MODEL USING THE GRID SERACH RESULTS\n",
        "### We plug in the results from the dictionary that holds the best_results_\n",
        "model_1 = RandomForestClassifier(n_estimators=results_1['n_estimators'],\\\n",
        "                                 max_depth=results_1['max_depth'],\\\n",
        "                                 min_samples_leaf=results_1['min_samples_leaf'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lofU9OqyQveS"
      },
      "source": [
        "# $\\underline{{\\rm Exercise\\ A.}}$\n",
        "Please complete the procedure! Your turn to do the:\n",
        "- fitting\n",
        "- prediction\n",
        "- evaluate the model using a confusion matrix and a numerical score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEEfxtDFQveS"
      },
      "source": [
        "You can read all about the RF Classifier here:\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_hQmrQxQveU"
      },
      "source": [
        "# 2.  $\\underline{{\\rm Splitting\\ Imbalanced\\ Data}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFBRQOOYQveU"
      },
      "source": [
        "What happens if our data is seriously imbalanced?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1z9U61SQveU"
      },
      "outputs": [],
      "source": [
        "blob_dist=np.array([200, 150, 125, 100, 40, 20, 12, 10, 5, 4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "niPdRIZUQveU"
      },
      "outputs": [],
      "source": [
        "pos, colors = make_blobs(n_samples=blob_dist,\n",
        "                  random_state=0, cluster_std=1.5)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.scatter(pos[:, 0], pos[:, 1], c=colors, s=50, cmap='rainbow');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoPgYblGQveU"
      },
      "source": [
        "let's see what happens in a standard 80/20 train test split:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmVgFj1uQveU"
      },
      "outputs": [],
      "source": [
        "colors.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipCfyf3rQveU"
      },
      "outputs": [],
      "source": [
        "features_blobs = np.zeros((colors.shape[0], 2))\n",
        "features_blobs[:,0] =colors\n",
        "features_blobs[:,1] = pos[:,1]\n",
        "target_blobs = pos[:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a611sUJkQveV"
      },
      "outputs": [],
      "source": [
        "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(features_blobs, target_blobs,\\\n",
        "                                                                    test_size=0.2,\\\n",
        "                                                                    random_state=seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQGsjdTNQveV"
      },
      "source": [
        "We know that there are 10, colors, so let's check the color values of the whole data set\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1wcKCfmQveV"
      },
      "outputs": [],
      "source": [
        "# color values of whole data set\n",
        "np.unique(colors, return_counts=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "au3p9JdcQveV"
      },
      "source": [
        "And now let's make sure that all color values made it to the test set.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrBuRhWlQveV"
      },
      "outputs": [],
      "source": [
        "# these are the color values represented in the test set....\n",
        "np.unique(X_test_2[:,0], return_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jy9ioTryQveV"
      },
      "outputs": [],
      "source": [
        "#compare to what's in the training set...\n",
        "np.unique(X_train_2[:,0], return_counts=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8n_rYMRQveV"
      },
      "source": [
        "### We can make sure that all \"classes\" are represented in both the training and test set by using stratification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGCGaG62QveV"
      },
      "source": [
        "## 3.1 Stratified KFold\n",
        "\n",
        "We can use a stratified KFold cross-validation generator to make sure all classes are included in the 5-KFolds during cross-validation.\n",
        "\n",
        "You implement something like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXRpCNWXQveV"
      },
      "outputs": [],
      "source": [
        "strat_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rag90lxtQveV"
      },
      "source": [
        "And when creating the test/train split, you set the keyword \"stratify=\" and you set it equal to the property you want to make sure is represented in both trainining and test sets.\n",
        "\n",
        "This can be EITHER a feature OR a target:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shXHfOJUQveV"
      },
      "outputs": [],
      "source": [
        "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(features_blobs, target_blobs,\\\n",
        "                                                            test_size=0.2,\\\n",
        "                                                            stratify=features_blobs[:,0],\\\n",
        "                                                            random_state=seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zz7aC_SSQveV"
      },
      "source": [
        "And now let's see the features in our test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVHjUQS2QveV"
      },
      "outputs": [],
      "source": [
        "np.unique(X_test_3[:,0], return_counts=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_Y1UeP3QveS"
      },
      "source": [
        "# 3.  $\\underline{{\\rm The\\ Random\\ Forest\\ Regressor}}$\n",
        "\n",
        "The RF is a powerful regression tool.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaTt7ekEQveT"
      },
      "source": [
        "## 3.1 How can we turn this into a regression problem?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z33ZhJd0QveT"
      },
      "outputs": [],
      "source": [
        "pos, colors = make_blobs(n_samples=1000, centers=50,\n",
        "                  random_state=0, cluster_std=1.5)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.scatter(pos[:, 0], pos[:, 1], c=colors, s=50, cmap='rainbow');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oaxc3WasQveT"
      },
      "outputs": [],
      "source": [
        "features_reg = np.zeros((colors.shape[0],2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKkhoPoTQveT"
      },
      "outputs": [],
      "source": [
        "features_reg[:,0] = colors\n",
        "features_reg[:,1] = pos[:,1]\n",
        "target_reg = pos[:,0] #now I've made the target a \"continuous\" variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uhl29rEzQveT"
      },
      "outputs": [],
      "source": [
        "plt.hist(target_reg);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMfBk-mOQveT"
      },
      "source": [
        "This is a nice \"bell\"-like distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalizing data\n",
        "\n",
        "What can we do if the range in our feature values is very large?\n",
        "\n",
        "We can normalize our data!"
      ],
      "metadata": {
        "id": "oi8x8TniAozI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### we can transform the data so it keeps the same distribution but we limit the range\n",
        "### common normalizing strategies:\n",
        "- for very large (or very small), i.e, $10^{12}$ or $10^{-5}$, we often just take the log base 10 of the values!\n",
        "\n",
        "$log_{10}(y)$\n",
        "\n",
        "- limit the range of the data between 0 and 1 with the function:\n",
        "\n",
        "$y_{\\rm norm} = \\frac{y - y_{\\rm min}}{y_{\\rm max} - y_{\\rm min}}$"
      ],
      "metadata": {
        "id": "_UAPYOXmA9Cj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's write a norming function"
      ],
      "metadata": {
        "id": "0xDytG-mCZrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def norm_func(array):\n",
        "  '''This function takes a 1D array and normalizes the elements\n",
        "  such that they maintain the same distribution but range from 0 to 1\n",
        "  '''\n",
        "  n = (array - np.min(array))/(np.max(array)-np.min(array))\n",
        "  return n"
      ],
      "metadata": {
        "id": "SQufS9iIA8SO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here's our data\n",
        "for i in range(features_reg.shape[1]):\n",
        "  plt.hist(features_reg[:,i], alpha=0.5)"
      ],
      "metadata": {
        "id": "nDyZT32zAGLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here's our normed data\n",
        "### DESCRIBE THE OUTPUT COMPARED TO THAT ABOVE\n",
        "feature_0_normed = norm_func(features_reg[:,0])\n",
        "feature_1_normed = norm_func(features_reg[:,1])\n",
        "\n",
        "plt.hist(feature_0_normed, alpha=0.5)\n",
        "plt.hist(feature_1_normed, alpha=0.5);"
      ],
      "metadata": {
        "id": "TKHmduZTDB5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cISuN29LQveT"
      },
      "source": [
        "# $\\underline{{\\rm Exercise\\ B.}}$\n",
        "Run the complete Random Forest Regressor training.\n",
        "- split the data\n",
        "- get best params from a grid search, you will need to change your estimator and score !\n",
        "- make the model\n",
        "- fit the model\n",
        "- get predictions from the model\n",
        "- evaluate the model using a numerical score\n",
        "- make a sctatter plot of true values on the x-axis and predictions on the y-axis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mnb-hf9TQveU"
      },
      "source": [
        "## 3.2 The feature importance attribute!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clu8hHRPQveU"
      },
      "outputs": [],
      "source": [
        "### CHANGE TO THE NAME OF YOUR MODEL\n",
        "importances = model_reg.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "# Print the feature ranking\n",
        "print(\"Feature ranking:\")\n",
        "\n",
        "for f in range(features_reg.shape[1]):\n",
        "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
        "\n",
        "# Plot the feature importances of the forest\n",
        "plt.figure(figsize=(16,6))\n",
        "plt.title(\"Feature importances\")\n",
        "plt.bar(range(features_reg.shape[1]), importances[indices],\n",
        "       color=\"r\", align=\"center\")\n",
        "plt.xticks(range(features_reg.shape[1]), indices)\n",
        "plt.xlim([-1, features_reg.shape[1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SPn8AaMQveU"
      },
      "source": [
        "This feature importance plot isn't too exciting because there are only two features. But it can be a powerful tool for analyzing results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05Y58N6cQveV"
      },
      "source": [
        "# $\\underline{{\\rm Exercise\\ C.}}$: Discussion\n",
        "\n",
        "What happens if we have imbalanced data in a regression problem? How would we know our data is imbalanced if there are no classses? What might we do to address the imbalance if we can't use stratification?\n",
        "\n",
        "* You only need to jot your ideas down, this exercise doesn't involve code\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fiVvnH0aQveV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:cluster_env]",
      "language": "python",
      "name": "conda-env-cluster_env-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}