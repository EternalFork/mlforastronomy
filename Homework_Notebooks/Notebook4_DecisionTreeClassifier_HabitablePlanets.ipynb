{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_eusFShj4Ek"
      },
      "source": [
        "# Notebook 4: Decision Trees | Habitable Planets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJJ29EPYIZPo"
      },
      "source": [
        "### This notebook is adapted from our course textbook.\n",
        "\n",
        "It accompanies Chapter 3 of the book.\n",
        "\n",
        "Data for this exercise come from [the Planet Habitability Lab](https://phl.upr.edu/projects/habitable-exoplanets-catalog).\n",
        "\n",
        "Copyright: Viviana Acquaviva (2023)\n",
        "\n",
        "License: [BSD-3-clause](https://opensource.org/license/bsd-3-clause/)\n",
        "\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9E8nPFmj4En"
      },
      "source": [
        "#### Please upload your completed notebook to Canvas as an .ipynb file\n",
        "#### Title the file as: LastName_notebook4.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2jhJKbJj4En"
      },
      "source": [
        "### Original work statement:\n",
        "\n",
        "Please write your name and the names of your collaborators in this cell.\n",
        "\n",
        "Please be sure to cite sources along the way as appropriate.\n",
        "\n",
        "### Your name:\n",
        "#### Collaborators:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I83-QtrEj4En"
      },
      "source": [
        "You can edit this notebook directly by adding code and text cells as needed. As always, begin by importing the necessary packages.\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDKc1h8Dj4Ep"
      },
      "source": [
        "# Problem 1: Preliminary data exploration and visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sH1wbpSIZPq"
      },
      "source": [
        "## 1.1 load the exoplanet.csv file\n",
        "### We use a selection of data from [the Planet Habitability Lab](https://phl.upr.edu/projects/habitable-exoplanets-catalog).\n",
        "\n",
        "This file contains data from an exoplanet catalog.\n",
        "\n",
        "The file contains 4 columns:\n",
        "- The first column, S_MASS, is star mass  in units of $M_{\\odot}$\n",
        "- The second column, P_PERIOD, is the orbital period of the planet in [days]\n",
        "- The third column, P_DISTANCE, is the distance from the planet to the host star in [AU]\n",
        "- The fourth column, P_HABITABLE, has a binary value for whether the planet is habitable or not. 0-not habitable, 1-habitable.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXHCwG0DLaXg"
      },
      "source": [
        "Here is a way of showing summary statistics by class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQxclteBIZPv"
      },
      "source": [
        "## 1.2 Create variables to hold the features and targets\n",
        "Your features will be 'S_MASS', 'P_PERIOD', 'P_DISTANCE'.\n",
        "\n",
        "Your target will be 'P_HABITABLE'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t_PvLE7IZPy"
      },
      "source": [
        "## 1.3 Make a histogram of the features.\n",
        "note: take a look at df.head() to print out the first 5 rows, you may need to make three separate histograms if the ranges of the features are too different!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sihA09cIZPy"
      },
      "source": [
        "Non-pro tip: when you plot a distribution in a histogram, and the x-range seems unnecessarily large, it means that there are outliers! :)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Questions:\n",
        "What do you notice about their distribution? Is there anything that might make the classification problem challenging?"
      ],
      "metadata": {
        "id": "d9aBdgdsp4GU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcXhMPi0IZP1",
        "outputId": "a648025c-7f3f-423c-f8c0-4eee52a1e9fb"
      },
      "source": [
        "## 1.4 Check the distribution or counts of the target.\n",
        "\n",
        "### Question:\n",
        "This is a binary classification problem. Are the two outcomes equally probable?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PjcgL69IZP2"
      },
      "source": [
        "### Question:     \n",
        "What kind of performance can we expect (qualitatively, is the information sufficient?) Do you expect to have latent (hidden) variables that might affect the outcome beyond those that we have?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d-uLHZ7IZP3"
      },
      "source": [
        "# Problem 2: Perform Decision Tree Classification\n",
        "## 2.1\n",
        "a. Begin with a random train/test split. Make and 80/20 train test split, remember to use a random_state.\n",
        "\n",
        "b. make a histogram (or check the counts) of the targets in the training and test set.\n",
        "\n",
        "c. define your model\n",
        "\n",
        "d. fit your model\n",
        "\n",
        "e. make predictions for the test features\n",
        "\n",
        "f. evaluate your model on the test targets using an accuracy score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFgwgmeEIZP3"
      },
      "source": [
        "Let's pick the Decision Tree method ( don't fprget to fix random state) and build the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMX1YSN-IZP5"
      },
      "source": [
        "# Problem 3: Analysis\n",
        "## 3.1 Plot the confusion matrix.\n",
        "\n",
        "* Note that so far, we use the predictions on *one* test fold, so the numbers will refer to the test set only."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVPd9iP8j4Es"
      },
      "source": [
        "## 3.2 Repeat steps in 2.1 but using a 50/50 train/test split, and a 85/15 train/test split."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: Be sure to define the variables that hold your other models by different names. We do not want to get our models mixed-up."
      ],
      "metadata": {
        "id": "RB_DUb1TtJWx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question:\n",
        "What happens to the accuracy? Would you expect the accuracy to go up or down as your training set becomes larger?"
      ],
      "metadata": {
        "id": "QndmrcoxZ401"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYrVFJ1EIZP5"
      },
      "source": [
        "## 3.4  Implement two types of k-fold Cross Validation.\n",
        "\n",
        "Note: remember to fix the random seed for exactly reproducible behavior.\n",
        "\n",
        "a. Create two cross-validation generators. One using the 5 k-fold split like we've been doing in class. For the second one use the StratifiedKFold(). You will need to import it like this:\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "Then implement it with the same keywords as the KFold().\n",
        "\n",
        "** STRATIFICATION ensures that the class distributions in each split resembles those of the\n",
        "ENTIRE data set\n",
        "\n",
        "b. Perform cross-validation two times, once using the KFold split and another using the StratifiedKFold. Print the training and testing scores as usual and compare.\n",
        "\n",
        "### Question:\n",
        "Did changing the cross-validation generator affect the scores significantly?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvYL7VvGIZP7"
      },
      "source": [
        "#### Question: are the differences between the two kinds of Kfold splits statistically significant?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7SglIALIZP8"
      },
      "source": [
        "## 3.5 Let's now use recall as our scoring parameter.\n",
        "### Question:\n",
        "How would you evaluate the model based on the result from the recall scores vs the accuracy scores?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYvZtArZIZQA"
      },
      "source": [
        "# Problem 4:  Finally, plot the learning curves using the model with the 80/20 split and the stratified cv generator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UCaVWQBIZQA"
      },
      "source": [
        "Learning curves are helpful in order to visualize the training scores vs the test scores, and how they vary as a function of data set size. They allow us to determine whether we have enough learning data, AND whether we have a high bias or high variance problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nk8BWJ7zIZQB"
      },
      "source": [
        "# Problem 5. Conclusions: Is our Desicion Tree model suffering from high variance or high bias? What might you suggest for a next step and why?"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A3TH22RDs9je"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python [conda env:cluster_env]",
      "language": "python",
      "name": "conda-env-cluster_env-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}